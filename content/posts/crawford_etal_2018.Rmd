---
title: Hidden population size estimation from respondent-driven sampling\: a network approach
author: "Ari Decter-Frain"
date: "04/02/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Forrest Crawford, Jiacheng Wu, and Robert Heimer, 2018

I'm essentially summarizing this paper and Crawford's 2016 paper together, since the 2016 paper is essential background for understanding this paper. 

The 2016 paper begins from the premise that standard RDS assumptions (that sampling probability is a function of degree alone) do not adequately reflect the sampling process in RDS. Crawford lists several reasons for this:

* It is only unbiased given sampling with replacement, but in practice RDS is always carried out without replacement.

* It only becomes unbiased at "equilibrium". By equilibrium, we mean a point where recruitment chains are distributed throughout the network at random. The concept of equilibrium only really makes sense if we are sampling with replacement, which we're not, and if chains carry on indefinitely, which they don't. 

* It assumes seeds and recruitment occur at random in accordance with node degree. This only makes sense at equilibrium. In actuality, network structure and information about the current state of recruitment both heavily condition the progression of recruitment paths. For instance, when a node has no neighbors that are currently recruiting, it's probability of being sampled is zero. 

This motivates the need for fully recovering the "recruitment subgraph" that underlies the graph of recruited nodes, from which estimators can be constructed which make fewer assumptions about the network. The key point is that we only observe a fraction of the real edges in the network of recruited nodes - the ones along which recruitment occurs. The author also notes that we have more information at our disposal to estimate this subgraph than is typically considered in RDS statistical approaches. Specifically, we can learn something about the graph from the sequence of recruitments and the time between recruitments.

To recover this graph, the author constructs a likelihood function for the *times* between recruitments, which he shows can be described as a function of an exponential rate parameter and the underlying graph. Then, simple rearrangement of the likelihood yields that the adjacency matrix for the recruitment subgraph is a probabilistic function of the rate parameter, the observed set of times between recruitments, and the number of susceptible edges at each recruitment time. The unknowns in the problem are the rate parameter and the underlying subgraph, which can be estimated by maximum likelihood or by setting priors on each and sampling from the posterior within a Bayesian framework. 

---

The 2018 paper expands upon the subgraph modelling idea to develop an estimate of total population size. This paper starts by assuming the degree of each population member is binomially distributed, $d_i \sim Binomial(N - 1, p)$. The substantive assumption here is that edges are randomly distributed across the network. If we believe this, then we have a way of expressing the relationship between $d_i$, $p$, and $N$, which is the parameter of interest. This likelihood is combined with the likelihood from the previous paper for the adjacency matrix of the recruitment subgraph to construct a formulation that uses information about recruitment times, respondent degree, and the sequence of recruits to estimate N within a Bayesian framework.

--- 

The key contribution of these papers is to provide probabilistic models for estimating population size and recruitment subgraphs that closely reflect all the steps and sequencing involved in an RDS research design. Most other statistical models for RDS require an assumption of sampling with replacement and the recruitment sequence having achieved equilibrium. This model does not. Instead, it builds up from mechanically true assumptions about how RDS occurs in practice. In this way, the approach presented in these papers is innovative and useful. 

The main downside of the model that results from this procedure is that it ends up relying quite heavily on the exact timing of recruitments to learn about population size and the underlying network graph. Indeed, the likelihood function for the times between recruitment is central to both models. To the extent that recruitment timing is measured with error, this may pose problems for the model. For instance, if a user is recruited at time 1 but only takes the survey at time 2, we may not actually observe time 1, and time 2 actually reflects network information *and* individual differences in interest/willingness/intent to complete the survey. With this in mind, it seems the viability of this model might depend to some extent on the proximity between recruitment time and survey time.

This problem seems even more acute for a web-based RDS setting where people might instantly share a survey with their network by clicking the "share" button. In this case, all of the time between surveys being taken results from individual differences in respondents' tendency to respond. I'm not exactly sure what to think of this model in web-based setting.




